# from pathlib import Path
# import numpy as np
#
# # ê²½ë¡œ ì„¤ì •
# DATA_ROOT = Path("C:/Users/user/Desktop/skh/ETRI")
# GZ_PATH = DATA_ROOT / "processed_videos"
# INFO_PATH = DATA_ROOT / "PNU_selected"
# test_subjects = {
#     "A2-1022-5", "A2-1026-3", "A2-1026-04", "A2-1029-02", "A2-1029-03", "A2-1029-04", "A2-1029-05"
# }
# # event_infoì—ì„œ ë§ˆì§€ë§‰ ì¤„ì˜ ìˆ«ì ë¼ë²¨ íŒŒì‹±
# def parse_event_label(event_info_path):
#     try:
#         with open(event_info_path, 'r', encoding='utf-8') as f:
#             lines = f.readlines()
#             for line in reversed(lines):
#                 line = line.strip()
#                 if not line or line.startswith("#"):
#                     continue
#                 clean = line.split("#")[0].strip()
#                 if clean.isdigit():
#                     return int(clean)
#     except Exception as e:
#         print(f" label ë¡œë”© ì‹¤íŒ¨ ({event_info_path}): {e}")
#     return None
#
# X_train, y_train, id_train = [], [], []
# X_test, y_test, id_test = [], [], []
#
# # ëª¨ë“  event_info.txtë¥¼ ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰
# for event_info_path in INFO_PATH.rglob("event_info.txt"):
#     try:
#         event_id = event_info_path.parent.name  # ì˜ˆ: 000, 001
#         label = parse_event_label(event_info_path)
#         if label is None:
#             continue
#
#         # ê²½ë¡œë¡œë¶€í„° subject_name, session_id ì¶”ì¶œ
#         parts = event_info_path.parts
#         subject_name = parts[parts.index("PNU_selected") + 1]
#         session_id = parts[parts.index(subject_name) + 1]
#
#         print(f"\n subject: {subject_name}, session: {session_id}, event_id: {event_id} â†’ label = {label}")
#
#         # processed_videos í´ë”ì—ì„œ ì¼ì¹˜í•˜ëŠ” ëª¨ë“  í´ë” íƒìƒ‰
#         expected_prefix = f"processed_{subject_name}_{session_id}_rec_{event_id}_"
#         matched_folders = [
#             f for f in GZ_PATH.iterdir()
#             if f.name.startswith(expected_prefix) and f.name.endswith("_out_resnet_x128_vertex")
#         ]
#
#         if not matched_folders:
#             print(f" No matched folder for {expected_prefix}")
#             continue
#
#         for folder in sorted(matched_folders):
#             print(f" í›„ë³´: {folder.name}")
#             gaze_txt_path = folder / "predicted_gaze_vectors.txt"
#             print(f" ì°¾ì€ ê²½ë¡œ: {gaze_txt_path}")
#
#             if gaze_txt_path.exists():
#                 try:
#                     gaze_seq = np.loadtxt(gaze_txt_path, delimiter=',')
#                     print(f" gaze shape: {gaze_seq.shape}")
#                     MAX_LEN = 300  # ì „ì²´ í”„ë ˆì„ ê¸¸ì´ í†µì¼
#
#                     if gaze_seq.shape[0] <= MAX_LEN:
#                         padded = np.zeros((MAX_LEN, 3), dtype=np.float32)
#                         padded[:gaze_seq.shape[0]] = gaze_seq  # ì•ìª½ì— ì‹¤ì œ ê°’ ë„£ê³  ë‚˜ë¨¸ì§„ 0
#                         X_data.append(padded)
#                         y_data.append(label)
#                         id_data.append(folder.name)
#                         print(" ì €ì¥ ì™„ë£Œ (íŒ¨ë”©)")
#                     else:
#                         print(f"âš  í”„ë ˆì„ ìˆ˜ ì´ˆê³¼: {gaze_seq.shape[0]}")
#
#                 except Exception as e:
#                     print(f" gaze vector ë¡œë”© ì‹¤íŒ¨: {e}")
#             else:
#                 print(" gaze í…ìŠ¤íŠ¸ íŒŒì¼ ì—†ìŒ")
#
#     except Exception as e:
#         print(f" ì˜ˆì™¸ ë°œìƒ: {e}")
#
# print(f"\n ì´ ìˆ˜ì§‘ëœ ìƒ˜í”Œ ìˆ˜: {len(X_data)}")
#
# ###########################
# import torch
# import numpy as np
# from torch.utils.data import Dataset, DataLoader
# import torch.nn as nn
#
# #  CrossEntropyLossê°€ ì²˜ë¦¬ ê°€ëŠ¥í•œ ë¼ë²¨ë§Œ í•„í„°ë§
# X_data_filtered, y_data_filtered, id_data_filtered = [], [], []
#
# for x, y, vid in zip(X_data, y_data, id_data):
#     if y in [0, 1]:
#         X_data_filtered.append(x)
#         y_data_filtered.append(y)
#         id_data_filtered.append(vid)
#
# target_list = X_test if subject_name in test_subjects else X_train
# label_list = y_test if subject_name in test_subjects else y_train
# id_list    = id_test if subject_name in test_subjects else id_train
#
# target_list.append(padded)
# label_list.append(label)
# id_list.append(folder.name)
#
#
#
# print(f" ìµœì¢… ìƒ˜í”Œ ìˆ˜: {len(X_data)} / ë¼ë²¨ ì¢…ë¥˜: {set(y_data)}")
#
# # -----------------------------
# #  Dataset êµ¬ì„±
# # -----------------------------
# class GazeDataset(Dataset):
#     def __init__(self, X, y, ids):
#         self.X = torch.tensor(X, dtype=torch.float32)
#         self.y = torch.tensor(y, dtype=torch.long)
#         self.ids = ids  # ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸
#
#     def __len__(self):
#         return len(self.X)
#
#     def __getitem__(self, idx):
#         return self.X[idx], self.y[idx], self.ids[idx]
#
# # train_loader: í•™ìŠµìš© / eval_loader: ìˆœì„œ ê³ ì •ëœ í‰ê°€ìš©
# X_train = np.array(X_train)
# y_train = np.array(y_train)
# id_train = np.array(id_train)
#
# X_test = np.array(X_test)
# y_test = np.array(y_test)
# id_test = np.array(id_test)
#
# train_dataset = GazeDataset(X_train, y_train, id_train)
# test_dataset = GazeDataset(X_test, y_test, id_test)
#
# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
# eval_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)
#
#
#
# # -----------------------------
# #  LSTM ëª¨ë¸ ì •ì˜
# # -----------------------------
# class GazeLSTM(nn.Module):
#     def __init__(self, input_dim=3, hidden_dim=64, num_layers=1, num_classes=2):
#         super().__init__()
#         self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)
#         self.fc = nn.Linear(hidden_dim, num_classes)
#
#     def forward(self, x):
#         out, _ = self.lstm(x)
#         return self.fc(out[:, -1, :])
#
# # -----------------------------
# #  í•™ìŠµ ë£¨í”„
# # -----------------------------
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# model = GazeLSTM().to(device)
# criterion = nn.CrossEntropyLoss()
# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
#
# num_epochs = 100
# for epoch in range(num_epochs):
#     model.train()
#     total_loss, correct, total = 0, 0, 0
#
#     for X_batch, y_batch, _ in train_loader:
#         X_batch, y_batch = X_batch.to(device), y_batch.to(device)
#
#         logits = model(X_batch)
#         loss = criterion(logits, y_batch)
#
#         optimizer.zero_grad()
#         loss.backward()
#         optimizer.step()
#
#         total_loss += loss.item()
#         pred = torch.argmax(logits, dim=1)
#         correct += (pred == y_batch).sum().item()
#         total += y_batch.size(0)
#
#     acc = correct / total * 100
#     print(f" Epoch {epoch+1}: Loss = {total_loss:.4f}, Accuracy = {acc:.2f}%")
#
# # -----------------------------
# #  ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ
# # -----------------------------
# print("\n ì˜ˆì¸¡ ê²°ê³¼ (GT vs Pred)")
# model.eval()
# with torch.no_grad():
#     for X, y, vid in eval_loader:
#         X = X.to(device)
#         logits = model(X)
#         pred = torch.argmax(logits, dim=1).item()
#         gt = y.item()
#         status = "âœ…" if pred == gt else "âŒ"
#         print(f"â–¶ ì˜ìƒ: {vid[0]} / GT: {gt} / Pred: {pred} {status}")
from pathlib import Path
import numpy as np

# ê²½ë¡œ ì„¤ì •
DATA_ROOT = Path("C:/Users/user/Desktop/skh/ETRI")
GZ_PATH = DATA_ROOT / "processed_videos"
INFO_PATH = DATA_ROOT / "PNU_selected"

# # í…ŒìŠ¤íŠ¸ ëŒ€ìƒ subject ëª©ë¡
# test_subjects = {
#     "A2-1022-5", "A2-1026-3", "A2-1026-04", "A2-1029-02", "A2-1029-03", "A2-1029-04", "A2-1029-05"
# }

# event_info.txtì—ì„œ ë¼ë²¨ íŒŒì‹±
def parse_event_label(event_info_path):
    try:
        with open(event_info_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            for line in reversed(lines):
                line = line.strip()
                if not line or line.startswith("#"):
                    continue
                clean = line.split("#")[0].strip()
                if clean.isdigit():
                    return int(clean)
    except Exception as e:
        print(f"âŒ label ë¡œë”© ì‹¤íŒ¨ ({event_info_path}): {e}")
    return None

# ë°ì´í„° ì´ˆê¸°í™”
X_train, y_train, id_train = [], [], []
X_test, y_test, id_test = [], [], []

# ëª¨ë“  event_info.txt íƒìƒ‰
for event_info_path in INFO_PATH.rglob("event_info.txt"):
    try:
        event_id = event_info_path.parent.name  # ì˜ˆ: 000, 001
        label = parse_event_label(event_info_path)
        if label is None:
            continue

        # ê²½ë¡œì—ì„œ subject_name, session_id ì¶”ì¶œ
        parts = event_info_path.parts
        subject_name = parts[parts.index("PNU_selected") + 1]
        session_id = parts[parts.index(subject_name) + 1]

        print(f"\nğŸ“„ subject: {subject_name}, session: {session_id}, event_id: {event_id} â†’ label = {label}")

        expected_prefix = f"processed_{subject_name}_{session_id}_rec_{event_id}_"
        matched_folders = [
            f for f in GZ_PATH.iterdir()
            if f.name.startswith(expected_prefix) and f.name.endswith("_out_resnet_x128_vertex")
        ]

        if not matched_folders:
            print(f"ğŸš« No matched folder for {expected_prefix}")
            continue

        for folder in sorted(matched_folders):
            gaze_txt_path = folder / "predicted_gaze_vectors.txt"
            if not gaze_txt_path.exists():
                continue


            try:
                gaze_seq = np.loadtxt(gaze_txt_path, delimiter=',')
                MAX_LEN = 300
                if gaze_seq.shape[0] > MAX_LEN:
                    print(f"âš  í”„ë ˆì„ ìˆ˜ ì´ˆê³¼: {gaze_seq.shape[0]}")
                    continue

                padded = np.zeros((MAX_LEN, 3), dtype=np.float32)
                padded[:gaze_seq.shape[0]] = gaze_seq

                # í•™ìŠµ / í…ŒìŠ¤íŠ¸ ë¶„ë¦¬
                if label in [0, 1]:
                    target_list = X_test if subject_name in test_subjects else X_train
                    label_list = y_test if subject_name in test_subjects else y_train
                    id_list    = id_test if subject_name in test_subjects else id_train

                    target_list.append(padded)
                    label_list.append(label)
                    id_list.append(folder.name)
                    print(f"ğŸ“Œ ì €ì¥ ì™„ë£Œ â†’ {folder.name}")

            except Exception as e:
                print(f"âŒ gaze vector ë¡œë”© ì‹¤íŒ¨: {e}")

    except Exception as e:
        print(f"âš ï¸ ì˜ˆì™¸ ë°œìƒ: {e}")

print(f"\nâœ… í•™ìŠµ ìƒ˜í”Œ ìˆ˜: {len(X_train)}, í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {len(X_test)}")
import torch
import numpy as np
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn


print(f"âœ… ìµœì¢… í•™ìŠµ ìƒ˜í”Œ ìˆ˜: {len(X_train)} / ë¼ë²¨ ì¢…ë¥˜: {set(y_train)}")
print(f"âœ… ìµœì¢… í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {len(X_test)} / ë¼ë²¨ ì¢…ë¥˜: {set(y_test)}")


# -----------------------------
#  Dataset êµ¬ì„±
# -----------------------------
class GazeDataset(Dataset):
    def __init__(self, X, y, ids):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)
        self.ids = ids  # ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx], self.ids[idx]

# train_loader: í•™ìŠµìš© / eval_loader: ìˆœì„œ ê³ ì •ëœ í‰ê°€ìš©
X_train = np.array(X_train)
y_train = np.array(y_train)
id_train = np.array(id_train)

X_test = np.array(X_test)
y_test = np.array(y_test)
id_test = np.array(id_test)

train_dataset = GazeDataset(X_train, y_train, id_train)
test_dataset = GazeDataset(X_test, y_test, id_test)

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
eval_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)



# -----------------------------
#  LSTM ëª¨ë¸ ì •ì˜
# -----------------------------
class GazeLSTM(nn.Module):
    def __init__(self, input_dim=3, hidden_dim=64, num_layers=1, num_classes=2):
        super().__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_dim, num_classes)

    def forward(self, x):
        out, _ = self.lstm(x)               # out: [batch, seq_len, hidden_dim]
        final_feature = out.mean(dim=1)     # ì „ì²´ ì‹œì  í‰ê· 
        return self.fc(final_feature)


# -----------------------------
#  í•™ìŠµ ë£¨í”„
# -----------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = GazeLSTM().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

num_epochs = 100
for epoch in range(num_epochs):
    model.train()
    total_loss, correct, total = 0, 0, 0

    for X_batch, y_batch, _ in train_loader:
        X_batch, y_batch = X_batch.to(device), y_batch.to(device)

        logits = model(X_batch)
        loss = criterion(logits, y_batch)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        pred = torch.argmax(logits, dim=1)
        correct += (pred == y_batch).sum().item()
        total += y_batch.size(0)

    acc = correct / total * 100
    print(f" Epoch {epoch+1}: Loss = {total_loss:.4f}, Accuracy = {acc:.2f}%")

# -----------------------------
#  ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ
# -----------------------------
print("\n ì˜ˆì¸¡ ê²°ê³¼ (GT vs Pred)")
model.eval()
with torch.no_grad():
    for X, y, vid in eval_loader:
        video_name = vid[0]  # ë¬¸ìì—´ë¡œ ë³€í™˜ëœ í´ë” ì´ë¦„

        # âœ… íŠ¹ì • ì´ë¦„ë§Œ í•„í„°ë§
        if not (
                "000_000036592912" in video_name or
                "001_000336294412" in video_name
        ):
            continue  # ë‚˜ë¨¸ì§€ëŠ” ìŠ¤í‚µ
        X = X.to(device)
        logits = model(X)
        pred = torch.argmax(logits, dim=1).item()
        gt = y.item()
        status = "âœ…" if pred == gt else "âŒ"
        print(f"â–¶ ì˜ìƒ: {vid[0]} / GT: {gt} / Pred : {pred} {status}")